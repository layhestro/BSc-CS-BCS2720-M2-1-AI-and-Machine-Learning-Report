\subsection{Time-predictor Discussion}
Research question 1 focuses on predicting the duration of training runs.
In this context, training duration refers to the wall-clock time required to complete a fixed training budget defined by the maximum number of training steps (max steps), rather than time to convergence.
For this purpose, nine regression models were evaluated to predict training duration using cross-validation. Model performance was assessed using the coefficient of determination ($R²$) and mean absolute error (MAE). Figure X shows the comparison of R² scores across all models, while Figure Y presents the corresponding MAE values. Gradient Boosting achieved the highest R² (0.39) and the lowest MAE (2–3 minutes), outperforming linear models, k-nearest neighbors, and other ensemble methods.

5.1 Discussion — Training Duration Prediction (RQ1)
Gradient boostinf achieved the best performance for training distributation due to its anility to model complex non-linear relationships and interactions between inout features. Training duration in reinforcement learning is influenced by multiple factors that do not combine linearly, such as training budget, environment characteristics, and hardware constraints. Gradient boosting incrementally builds an ensemble of decision trees that correct constraints. Gradient boosting incrementally builds an ensemble of deicsion trees that correct previous errors, allowing it to capture subtle dependancies and interaction effetcs that are not well represented by linear models. In addition, tree-based boosting methods naturally handle mixed feature types and heterogeneous scales, making them well suited for datasets that combine numerical hyperparameters with categorical environment and hardware information.
Why R² is moderate but MAE is low
Although the selected model achieves a low mean absolute error, the corresponding R² remains moderate. This reflects the inherently stochastic nature of reinforcement learning training, where wall-clock duration is influenced by factors such as random environment dynamics, system load, and nondeterministic execution behavior that are not fully captured by the available features. As a result, while the model can accurately estimate typical training durations within a small absolute error margin, a substantial portion of the total variance in duration remains unexplained. In addition, rare but extreme long-running training instances disproportionately affect variance-based metrics such as R², further limiting the achievable explanatory power despite strong practical accuracy.
Interpretation of Feature Importance
The feature importance analysis provides insight into the primary drivers of training duration. The dominance of max steps reflects the fundamental structure of reinforcement learning training, where each additional interaction step directly increases computational workload and runtime. Environment type also plays an important role, as different environments vary in complexity, simulation cost, and physics calculations, leading to differences in time per step even when training budgets are comparable. In contrast, network architecture and optimization hyperparameters, such as learning rate, batch size, and number of layers, have a comparatively small impact on wall-clock training time. While these parameters strongly influence learning dynamics and performance, they do not substantially alter the number of environment interactions required, and therefore contribute less to overall training duration.
Discussion — Limitations and Failure Cases
Despite its strong performance for typical training runs, the proposed model exhibits limitations for extreme long-duration cases. Diagnostic analyses show a systematic underestimation of very long training runs, which can be attributed to data sparsity in this region, as such runs occur far less frequently in the dataset. This imbalance limits the model’s ability to generalize to rare, high-duration instances and results in increasing prediction variance for larger values. The presence of heteroscedasticity, where error variance grows with predicted duration, further highlights this limitation. Consequently, squared-error metrics such as RMSE are dominated by a small number of extreme outliers, leading to large RMSE values despite low mean absolute error and strong performance for the majority of training runs.

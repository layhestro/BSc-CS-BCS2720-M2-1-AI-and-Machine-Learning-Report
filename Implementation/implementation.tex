\section{Implementation}

\subsection{Software \& Data Pipeline}
The prediction pipelines for all research questions were implemented in Python using Google Colab. The core dependencies include:
\begin{itemize}
    \item \textbf{Data Processing}: pandas 2.2.2, numpy 2.0.2
    \item \textbf{Machine Learning}: scikit-learn (recent version) for all models, preprocessing, and metrics
    \item \textbf{Visualization}: matplotlib, seaborn
    \item \textbf{Storage}: Google Drive integration for persistent data; joblib for model serialization
\end{itemize}
All experiments used a fixed random seed (42) for reproducibility.

\subsection{Research Question 1: Duration Prediction Implementation}

This section describes the software implementation for predicting RL training duration based on configuration parameters and hardware specifications.

\subsubsection{Data Pipeline Architecture}
The implementation follows a modular pipeline structure with distinct stages:

\paragraph{Stage 1: Data Loading and Cleaning}
The master dataset containing 5,799 training runs is loaded from CSV format. Missing values are handled through domain-specific imputation:
\begin{itemize}
    \item Hardware features (\texttt{gpu\_available}, \texttt{gpu\_memory\_gb}) default to False and 0
    \item Numeric hyperparameters filled with 0 (appropriate for optional parameters)
    \item Rows with missing target values (\texttt{training\_duration\_seconds}) are dropped
\end{itemize}

After cleaning, the dataset contains 5,673 valid training runs with complete feature and target information.

\paragraph{Stage 2: Feature Engineering}
To prevent data leakage, features that could only be known after training completion are excluded from the predictor set (e.g., performance metrics, resource usage, timestamps). The final feature set contains 24 predictors including categorical features (\texttt{environment}, \texttt{algorithm}, \texttt{os}, \texttt{gpu\_name}) and numeric features.

\paragraph{Stage 3: Target Transformation}
Training durations range from 364 seconds to over 19 hours. To stabilize variance, we apply log transformation:
\begin{equation}
y_{transformed} = \log(1 + y_{seconds})
\end{equation}

\paragraph{Stage 4: Preprocessing Pipeline}
Categorical variables are encoded using OrdinalEncoder. No standardization is applied to numeric features, as tree-based models are scale-invariant.

\subsubsection{Cross-Validation Strategy}
We implement stratified 5-fold cross-validation \cite{kohavi1995study}. The stratification divides training durations into quintiles, ensuring each fold contains a balanced mix of short, medium, and long training runs.

\subsubsection{Model Registry}
We implement a model registry pattern to systematically compare algorithms:
\textbf{Linear Models:} Linear Regression (baseline), Ridge Regression (tuned $\alpha$).
\textbf{Tree-Based Ensembles:} Random Forest, Extra Trees, Gradient Boosting, HistGradient Boosting.
\textbf{Distance-Based Models:} K-Nearest Neighbors (grid search over $k$).

\subsubsection{Model Persistence and Outputs}
After cross-validation, the best-performing model (Gradient Boosting) is retrained on the complete dataset, serialized using joblib, and stored with preprocessing metadata.

\subsection{Research Question 2: Performance Prediction Implementation}

This section describes the software implementation for predicting final agent performance (mean reward).

\subsubsection{Data Pipeline}
The master dataset was loaded and preprocessed to focus on performance prediction. Missing values in the target variable (\texttt{final\_mean\_reward}) were removed. To prevent data leakage, post-training features (RAM, duration, etc.) were excluded.
Due to significant data imbalance, separate models were trained for PPO and SAC. Categorical features were encoded using LabelEncoder, and missing values in feature columns were filled with zero.

\subsubsection{Model Selection}
Six regression models were evaluated: K-Nearest Neighbors, Linear Regression, Multi-Layer Perceptron (100 hidden units, tanh activation), Random Forest, Extra Trees, and HistGradientBoostingRegressor.

\subsubsection{Cross-Validation Strategy}
Model performance was evaluated using 10-fold cross-validation with shuffling enabled. Performance was assessed using R² score and MAE.

\subsection{Research Question 3: RAM Prediction Implementation}

This section describes the software implementation for predicting peak RAM usage.

\subsubsection{Data Pipeline}
The master dataset was loaded and preprocessed to focus on RAM prediction. Missing values in \texttt{peak\_ram\_mb} were removed, and leakage features were dropped. As with RQ2, separate models were trained for PPO and SAC.

\subsubsection{Model Selection and Hyperparameters}\label{implmodelselectionrq3}
Six regression models were evaluated. For most models, scikit-learn default hyperparameters were used with exceptions to reduce overfitting:
\begin{itemize}
    \item \textbf{MLPRegressor}: Increased max\_iter to 1000
    \item \textbf{Random Forest \& Extra Trees}: Increased min\_samples\_split to 5, min\_samples\_leaf to 4
    \item \textbf{HistGradientBoostingRegressor}: Decreased max\_bins to 180, min\_samples\_leaf to 3
\end{itemize}

\subsubsection{Cross-Validation Strategy}
Model performance was evaluated using 10-fold cross-validation with shuffling enabled. Performance metrics (R² and MAE) were computed for each fold and averaged. The best-performing models were serialized using joblib.
\section{Introduction}

Reinforcement Learning (RL) has achieved remarkable success in domains ranging from game playing \cite{mnih2015human, silver2016mastering} to robotics \cite{levine2016end} and autonomous systems \cite{kiran2021deep}. However, a significant barrier to RL research is the computational cost of training agents. A single training run can require hours to days of computation, consuming substantial energy and financial resources. This challenge is exacerbated by the trial-and-error nature of hyperparameter tuning, where researchers must run multiple expensive experiments to find optimal configurations.

Currently, estimating the training time, final performance, and resource requirements of an RL agent relies heavily on expensive pilot experiments or intuition. Researchers often face uncertainty regarding how long a configuration will take, whether it will converge, or if it will exceed available memory. These uncertainties lead to wasted computational resources and slower research cycles.

\subsection{The Meta-Learning Approach}

We propose a meta-learning solution: using supervised machine learning to predict properties of RL training runs before execution. Rather than improving RL algorithms themselves, we treat RL training as a data-generating process and build predictive models that forecast training outcomes. The key hypothesis is that training outcomes are determined by systematic relationships between configuration parameters (learning rate, batch size, network architecture), environment characteristics, and hardware specifications.

\subsection{Contributions}

This work makes the following contributions:

\begin{itemize}
    \item We formulate three critical prediction problems in RL training as supervised learning tasks: (1) wall-clock training duration, (2) final agent performance, and (3) peak RAM usage.
    \item We develop a data collection pipeline that extracts training metadata, hyperparameters, and performance metrics from Unity ML-Agents training runs.
    \item We evaluate multiple regression models across all three research questions. We find that Gradient Boosting offers the best trade-off for duration prediction (low MAE), while Random Forest and Extra Trees excel at predicting agent performance. For RAM usage, we demonstrate that K-Nearest Neighbors and Random Forest can achieve near-perfect predictions ($R^2 > 0.95$) for specific algorithms.
    \item We provide feature importance analysis identifying key predictors, such as \texttt{max\_steps} for duration and algorithm-specific hyperparameters for memory consumption.
\end{itemize}

The remainder of this paper is organized as follows: Section 2 presents our research questions and methodology, Section 3 describes our implementation, Section 4 presents experimental results, Section 5 discusses findings and limitations, and Section 6 concludes with future directions.